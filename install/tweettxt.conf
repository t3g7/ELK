input {  
      file {
#      	codec => multiline {
#          pattern => "^\]" # Change to separate events
#          negate => true
#          what => previous               
#        }
        path => "/home/francois/Documents/Travail/GLRT/projet_S9/dm-twitter/datasets/tweets_dataset_20151027.json"
#	path => "/home/francois/Documents/Travail/GLRT/projet_S9/dm-twitter/datasets/tweets_dataset_20151026.json"
#	path => "/home/francois/Documents/Travail/GLRT/projet_S9/ELK/tweets.json"
 	type => "txt"
        start_position => "beginning"
	sincedb_path => "/dev/null"
      }
}

filter {

#       mutate {
#       	 replace => {"message" => "%{message}}"}
#	}

#      mutate {
#            gsub => [ "message","\[",""]
#            gsub => [ "message","\n",""]
#        }
 
#	ruby  {
#   	 init => "require 'json'"
#    	 code => "event['result'] = JSON.parse(event['event'])"
#	}
      
      json{
	source => "message"
      }
      
      mutate {
	add_field => ["event_timestamp",""]
      }

       ruby{
#	code => "str = event[created_at]"
	code => "event['event_timestamp'] = DateTime.parse event['created_at']"
#	code => "event['event_timestamp'] = DateTime.strptime(event['created_at'],'%a %b %d %H:%M:%S %z %Y')"	
       }

       mutate{
	gsub => ["[user][name]"," ","_"]
	gsub => ["[user][location]",",",""]
	gsub => ["[user][location]","-","_"]
	gsub => ["[user][location]"," ","_"]
       }


#       ruby{
#	code => "event['user.name'].gsub(' ','_')"
#       }

}

output {
    elasticsearch {
#	protocol => "http"
        host => "localhost"
#	port => "9200"
        workers => 1
        index => "logstash-twitter-bis"
    }
	stdout { codec=>json }
}
